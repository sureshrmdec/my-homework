<html><head>
<META http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<!--SafClassName="docSection1Title"--><!--SafTocEntry="7.5 Generic Socket Options"-->
<link rel="STYLESHEET" type="text/css" href="FILES/style.css">
<link rel="STYLESHEET" type="text/css" href="FILES/docsafari.css">
<style type="text/css">	.tt1    {font-size: 10pt;}</style>
</head>
<body>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
	<a href="0131411551_ch07lev1sec4.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
	<a href="0131411551_ch07lev1sec6.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
<br>
<table width="100%" border="0" cellspacing="0" cellpadding="0"><tr><td valign="top"><A NAME="ch07lev1sec5"></A>
<H3 class="docSection1Title" id="162666-918">7.5 Generic Socket Options</H3>
<P class="docText">We start with a discussion of the generic socket options. These options are protocol-independent (that is, they are handled by the protocol-independent code within the kernel, not by one particular protocol module such as IPv4), but some of the options apply to only certain types of sockets. For example, even though the <TT>SO_BROADCAST</TT> socket option is called "generic," it applies only to datagram sockets.</P>
<A NAME="ch07lev2sec1"></A>
<H4 class="docSection2Title"> <TT>SO_BROADCAST</TT> Socket Option</H4>
<P class="docText">This option enables or disables the ability of the process to send broadcast messages. Broadcasting is supported for only datagram sockets and only on networks that support the concept of a broadcast message (e.g., Ethernet, token ring, etc.). You cannot broadcast on a point-to-point link or any connection-based transport protocol such as SCTP or TCP. We will talk more about broadcasting in <A class="docLink" HREF="0131411551_ch20.html#ch20">Chapter 20</A>.</P>
<P class="docText">Since an application must set this socket option before sending a broadcast datagram, it prevents a process from sending a broadcast when the application was never designed to broadcast. For example, a UDP application might take the destination IP address as a command-line argument, but the application never intended for a user to type in a broadcast address. Rather than forcing the application to try to determine if a given address is a broadcast address or not, the test is in the kernel: If the destination address is a broadcast address and this socket option is not set, <TT>EACCES</TT> is returned (p. 233 of TCPv2).</P>

<A NAME="ch07lev2sec2"></A>
<H4 class="docSection2Title"> <TT>SO_DEBUG</TT> Socket Option</H4>
<P class="docText">This option is supported only by TCP. When enabled for a TCP socket, the kernel keeps track of detailed information about all the packets sent or received by TCP for the socket. These are kept in a circular buffer within the kernel that can be examined with the <TT>trpt</TT> program. Pages 916–920 of TCPv2 provide additional details and an example that uses this option.</P>

<A NAME="ch07lev2sec3"></A>
<H4 class="docSection2Title"> <TT>SO_DONTROUTE</TT> Socket Option</H4>
<P class="docText">This option specifies that outgoing packets are to bypass the normal routing mechanisms of the underlying protocol. For example, with IPv4, the packet is directed to the appropriate local interface, as specified by the network and subnet portions of the destination address. If the local interface cannot be determined from the destination address (e.g., the destination is not on the other end of a point-to-point link, or is not on a shared network), <TT>ENETUNREACH</TT> is returned.</P>
<P class="docText">The equivalent of this option can also be applied to individual datagrams using the <TT>MSG_DONTROUTE</TT> flag with the <TT>send</TT>, <TT>sendto</TT>, or <TT>sendmsg</TT> functions.</P>
<P class="docText">This option is often used by routing daemons (e.g., <TT>routed</TT> and <TT>gated</TT>) to bypass the routing table and force a packet to be sent out a particular interface.</P>

<A NAME="ch07lev2sec4"></A>
<H4 class="docSection2Title"> <TT>SO_ERROR</TT> Socket Option</H4>
<P class="docText">When an error occurs on a socket, the protocol module in a Berkeley-derived kernel sets a variable named <TT>so_error</TT> for that socket to one of the standard Unix <TT>E</TT><span class="docEmphasis">xxx</span> values. This is called the <span class="docEmphasis">pending error</span> for the socket. The process can be immediately notified of the error in one of two ways:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList">If the process is blocked in a call to <TT>select</TT> on the socket (<A class="docLink" HREF="0131411551_ch06lev1sec3.html#ch06lev1sec3">Section 6.3</A>), for either readability or writability, <TT>select</TT> returns with either or both conditions set.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">If the process is using signal-driven I/O (<A class="docLink" HREF="0131411551_ch25.html#ch25">Chapter 25</A>), the <TT>SIGIO</TT> signal is generated for either the process or the process group.</P></span></LI></OL></span>
<P class="docText">The process can then obtain the value of <TT>so_error</TT> by fetching the <TT>SO_ERROR</TT> socket option. The integer value returned by <TT>getsockopt</TT> is the pending error for the socket. The value of <TT>so_error</TT> is then reset to 0 by the kernel (p. 547 of TCPv2).</P>
<P class="docText">If <TT>so_error</TT> is nonzero when the process calls <TT>read</TT> and there is no data to return, <TT>read</TT> returns–1 with <TT>errno</TT> set to the value of <TT>so_error</TT> (p. 516 of TCPv2). The value of <TT>so_error</TT> is then reset to 0. If there is data queued for the socket, that data is returned by <TT>read</TT> instead of the error condition. If <TT>so_error</TT> is nonzero when the process calls <TT>write</TT>, –1 is returned with <TT>errno</TT> set to the value of <TT>so_error</TT> (p. 495 of TCPv2) and <TT>so_error</TT> is reset to 0.</P>
<BLOCKQUOTE><P><P class="docList">There is a bug in the code shown on p. 495 of TCPv2 in that <TT>so_error</TT> is not reset to 0. This has been fixed in most modern releases. Anytime the pending error for a socket is returned, it must be reset to 0.</P></P></BLOCKQUOTE>
<P class="docText">This is the first socket option that we have encountered that can be fetched but cannot be set.</P>

<A NAME="ch07lev2sec5"></A>
<H4 class="docSection2Title"> <TT>SO_KEEPALIVE</TT> Socket Option</H4>
<P class="docText">When the keep-alive option is set for a TCP socket and no data has been exchanged across the socket in either direction for two hours, TCP automatically sends a <span class="docEmphasis">keep-alive probe</span> to the peer. This probe is a TCP segment to which the peer must respond. One of three scenarios results:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList">The peer responds with the expected ACK. The application is not notified (since everything is okay). TCP will send another probe following another two hours of inactivity.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">The peer responds with an RST, which tells the local TCP that the peer host has crashed and rebooted. The socket's pending error is set to <TT>ECONNRESET</TT> and the socket is closed.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">There is no response from the peer to the keep-alive probe. Berkeley-derived TCPs send 8 additional probes, 75 seconds apart, trying to elicit a response. TCP will give up if there is no response within 11 minutes and 15 seconds after sending the first probe.</P><BLOCKQUOTE><P><P class="docList">HP-UX 11 treats the keep-alive probes in the same way as it would treat data, sending the second probe after a retransmission timeout and doubling the timeout for each packet until the configured maximum interval, with a default of 10 minutes.</P></P></BLOCKQUOTE><P class="docList">If there is no response at all to TCP's keep-alive probes, the socket's pending error is set to <TT>ETIMEDOUT</TT> and the socket is closed. But if the socket receives an ICMP error in response to one of the keep-alive probes, the corresponding error (<A class="docLink" HREF="0131411551_app01lev1sec6.html#app01fig15">Figures A.15</A> and <A class="docLink" HREF="0131411551_app01lev1sec6.html#app01fig16">A.16</A>) is returned instead (and the socket is still closed). A common ICMP error in this scenario is "host unreachable," indicating that the peer host is unreachable, in which case, the pending error is set to <TT>EHOSTUNREACH</TT>. This can occur either because of a network failure or because the remote host has crashed and the last-hop router has detected the crash.</P></span></LI></OL></span>
<P class="docText">Chapter 23 of TCPv1 and pp. 828–831 of TCPv2 contain additional details on the keep-alive option.</P>
<P class="docText">Undoubtedly the most common question regarding this option is whether the timing parameters can be modified (usually to reduce the two-hour period of inactivity to some shorter value). Appendix E of TCPv1 discusses how to change these timing parameters for various kernels, but be aware that most kernels maintain these parameters on a per-kernel basis, not on a per-socket basis, so changing the inactivity period from 2 hours to 15 minutes, for example, will affect <span class="docEmphasis">all</span> sockets on the host that enable this option. However, such questions usually result from a misunderstanding of the purpose of this option.</P>
<P class="docText">The purpose of this option is to detect if the peer <span class="docEmphasis">host</span> crashes or becomes unreachable (e.g., dial-up modem connection drops, power fails, etc.). If the peer <span class="docEmphasis">process</span> crashes, its TCP will send a FIN across the connection, which we can easily detect with <TT>select</TT>. (This was why we used <TT>select</TT> in <A class="docLink" HREF="0131411551_ch06lev1sec4.html#ch06lev1sec4">Section 6.4</A>.) Also realize that if there is no response to any of the keep-alive probes (scenario 3), we are not guaranteed that the peer host has crashed, and TCP may well terminate a valid connection. It could be that some intermediate router has crashed for 15 minutes, and that period of time just happens to completely overlap our host's 11-minute and 15-second keep-alive probe period. In fact, this function might more properly be called "make-dead" rather than "keep-alive" since it can terminate live connections.</P>
<P class="docText">This option is normally used by servers, although clients can also use the option. Servers use the option because they spend most of their time blocked waiting for input across the TCP connection, that is, waiting for a client request. But if the client host's connection drops, is powered off, or crashes, the server process will never know about it, and the server will continually wait for input that can never arrive. This is called a <span class="docEmphasis">half-open connection</span>. The keep-alive option will detect these half-open connections and terminate them.</P>
<P class="docText">Some servers, notably FTP servers, provide an application timeout, often on the order of minutes. This is done by the application itself, normally around a call to <TT>read</TT>, reading the next client command. This timeout does not involve this socket option. This is often a better method of eliminating connections to missing clients, since the application has complete control if it implements the timeout itself.</P>
<BLOCKQUOTE><P><P class="docList">SCTP has a <span class="docEmphasis">heartbeat</span> mechanism that is similar to TCP's "keep-alive" mechanism. The heartbeat mechanism is controlled through parameters of the <TT>SCTP_SET_PEER_ADDR_PARAMS</TT> socket option discussed later in this chapter, rather than the <TT>SO_KEEPALIVE</TT> socket option. The settings made by <TT>SO_KEEPALIVE</TT> on a SCTP socket are ignored and do not affect the SCTP heartbeat mechanism.</P></P></BLOCKQUOTE>
<P class="docText"><A class="docLink" HREF="#ch07fig06">Figure 7.6</A> summarizes the various methods that we have to detect when something happens on the other end of a TCP connection. When we say "using <TT>select</TT> for readability," we mean calling <TT>select</TT> to test whether a socket is readable.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig06"></A>Figure 7.6. Ways to detect various TCP conditions.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="289" src="FILES/07fig06.jpg" ALT="graphics/07fig06.jpg"></p>

</CENTER>

<A NAME="ch07lev2sec6"></A>
<H4 class="docSection2Title"> <TT>SO_LINGER</TT> Socket Option</H4>
<P class="docText">This option specifies how the <TT>close</TT> function operates for a connection-oriented protocol (e.g., for TCP and SCTP, but not for UDP). By default, <TT>close</TT> returns immediately, but if there is any data still remaining in the socket send buffer, the system will try to deliver the data to the peer.</P>
<P class="docText">The <TT>SO_LINGER</TT> socket option lets us change this default. This option requires the following structure to be passed between the user process and the kernel. It is defined by including <TT>&lt;sys/socket.h&gt;</TT>.</P>
<pre>

</pre><pre>
struct linger {
  int   l_onoff;        /* 0=off, nonzero=on */
  int   l_linger;       /* linger time, POSIX specifies units as seconds */
};
</pre><pre>
</pre>
<P class="docText">Calling <TT>setsockopt</TT> leads to one of the following three scenarios, depending on the values of the two structure members:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList">If <TT>l_onoff</TT> is 0, the option is turned off. The value of <TT>l_linger</TT> is ignored and the previously discussed TCP default applies: <TT>close</TT> returns immediately.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">If <TT>l_onoff</TT> is nonzero and <TT>l_linger</TT> is zero, TCP aborts the connection when it is closed (pp. 1019–1020 of TCPv2). That is, TCP discards any data still remaining in the socket send buffer and sends an RST to the peer, not the normal four-packet connection termination sequence (<A class="docLink" HREF="0131411551_ch02lev1sec6.html#ch02lev1sec6">Section 2.6</A>). We will show an example of this in <A class="docLink" HREF="0131411551_ch16lev1sec6.html#ch16fig21">Figure 16.21</A>. This avoids TCP's TIME_WAIT state, but in doing so, leaves open the possibility of another incarnation of this connection being created within 2MSL seconds (<A class="docLink" HREF="0131411551_ch02lev1sec7.html#ch02lev1sec7">Section 2.7</A>) and having old duplicate segments from the just-terminated connection being incorrectly delivered to the new incarnation.</P><P class="docList">SCTP will also do an abortive close of the socket by sending an ABORT chunk to the peer (see Section 9.2 of [Stewart and Xie 2001]) when <TT>l_onoff</TT> is nonzero and <TT>l_linger</TT> is zero.</P><BLOCKQUOTE><P><P class="docList">Occasional USENET postings advocate the use of this feature just to avoid the TIME_WAIT state and to be able to restart a listening server even if connections are still in use with the server's well-known port. This should NOT be done and could lead to data corruption, as detailed in RFC 1337 [Braden 1992]. Instead, the <TT>SO_REUSEADDR</TT> socket option should always be used in the server before the call to <TT>bind</TT>, as we will describe shortly. The TIME_WAIT state is our friend and is there to help us (i.e., to let old duplicate segments expire in the network). Instead of trying to avoid the state, we should understand it (<A class="docLink" HREF="0131411551_ch02lev1sec7.html#ch02lev1sec7">Section 2.7</A>).</P></P><P><P class="docList">There are certain circumstances which warrant using this feature to send an abortive close. One example is an RS-232 terminal server, which might hang forever in CLOSE_WAIT trying to deliver data to a struck terminal port, but would properly reset the stuck port if it got an RST to discard the pending data.</P></P></BLOCKQUOTE></span></LI><LI><span style="font-weight:normal"><P class="docList">If <TT>l_onoff</TT> is nonzero and <TT>l_linger</TT> is nonzero, then the kernel will <span class="docEmphasis">linger</span> when the socket is closed (p. 472 of TCPv2). That is, if there is any data still remaining in the socket send buffer, the process is put to sleep until either: (i) all the data is sent and acknowledged by the peer TCP, or (ii) the linger time expires. If the socket has been set to nonblocking (<A class="docLink" HREF="0131411551_ch16.html#ch16">Chapter 16</A>), it will not wait for the <TT>close</TT> to complete, even if the linger time is nonzero. When using this feature of the <TT>SO_LINGER</TT> option, it is important for the application to check the return value from <TT>close</TT>, because if the linger time expires before the remaining data is sent and acknowledged, <TT>close</TT> returns <TT>EWOULDBLOCK</TT> and any remaining data in the send buffer is discarded.</P></span></LI></OL></span>
<P class="docText">We now need to see exactly when a <TT>close</TT> on a socket returns given the various scenarios we looked at. We assume that the client writes data to the socket and then calls <TT>close</TT>. <A class="docLink" HREF="#ch07fig07">Figure 7.7</A> shows the default situation.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig07"></A>Figure 7.7. Default operation of <TT>close:</TT> it returns immediately.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="196" src="FILES/07fig07.gif" ALT="graphics/07fig07.gif"></p>

</CENTER>
<P class="docText">We assume that when the client's data arrives, the server is temporarily busy, so the data is added to the socket receive buffer by its TCP. Similarly, the next segment, the client's FIN, is also added to the socket receive buffer (in whatever manner the implementation records that a FIN has been received on the connection). But by default, the client's <TT>close</TT> returns immediately. As we show in this scenario, the client's <TT>close</TT> can return before the server reads the remaining data in its socket receive buffer. Therefore, it is possible for the server host to crash before the server application reads this remaining data, and the client application will never know.</P>
<P class="docText">The client can set the <TT>SO_LINGER</TT> socket option, specifying some positive linger time. When this occurs, the client's <TT>close</TT> does not return until all the client's data and its FIN have been acknowledged by the server TCP. We show this in <A class="docLink" HREF="#ch07fig08">Figure 7.8</A>.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig08"></A>Figure 7.8. <TT>close</TT> with <TT>SO_LINGER</TT> socket option set and <TT>l_linger</TT> a positive value.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="191" src="FILES/07fig08.gif" ALT="graphics/07fig08.gif"></p>

</CENTER>
<P class="docText">But we still have the same problem as in <A class="docLink" HREF="#ch07fig07">Figure 7.7</A>: The server host can crash before the server application reads its remaining data, and the client application will never know. Worse, <A class="docLink" HREF="#ch07fig09">Figure 7.9</A> shows what can happen when the <TT>SO_LINGER</TT> option is set to a value that is too low.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig09"></A>Figure 7.9. <TT>close</TT> with <TT>SO_LINGER</TT> socket option set and <TT>l_linger</TT> a small positive value.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="187" src="FILES/07fig09.gif" ALT="graphics/07fig09.gif"></p>

</CENTER>
<P class="docText">The basic principle here is that a successful return from <TT>close</TT>, with the <TT>SO_LINGER</TT> socket option set, only tells us that the data we sent (and our FIN) have been acknowledged by the peer TCP. This does <span class="docEmphasis">not</span> tell us whether the peer application has read the data. If we do not set the <TT>SO_LINGER</TT> socket option, we do not know whether the peer TCP has acknowledged the data.</P>
<P class="docText">One way for the client to know that the server has read its data is to call <TT>shutdown</TT> (with a second argument of <TT>SHUT_WR</TT>) instead of <TT>close</TT> and wait for the peer to <TT>close</TT> its end of the connection. We show this scenario in <A class="docLink" HREF="#ch07fig10">Figure 7.10</A>.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig10"></A>Figure 7.10. Using <TT>shutdown</TT> to know that peer has received our data.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="183" src="FILES/07fig10.gif" ALT="graphics/07fig10.gif"></p>

</CENTER>
<P class="docText">Comparing this figure to <A class="docLink" HREF="#ch07fig07">Figures 7.7</A> and <A class="docLink" HREF="#ch07fig08">7.8</A> we see that when we close our end of the connection, depending on the function called (<TT>close</TT> or <TT>shutdown</TT>) and whether the <TT>SO_LINGER</TT> socket option is set, the return can occur at three different times:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList"><TT>close</TT> returns immediately, without waiting at all (the default; <A class="docLink" HREF="#ch07fig07">Figure 7.7</A>).</P></span></LI><LI><span style="font-weight:normal"><P class="docList"><TT>close</TT> lingers until the ACK of our FIN is received (<A class="docLink" HREF="#ch07fig07">Figure 7.7</A>).</P></span></LI><LI><span style="font-weight:normal"><P class="docList"><TT>shutdown</TT> followed by a <TT>read</TT> waits until we receive the peer's FIN (<A class="docLink" HREF="#ch07fig10">Figure 7.10</A>).</P></span></LI></OL></span>
<P class="docText">Another way to know that the peer application has read our data is to use an <span class="docEmphasis">application-level acknowledgment</span>, or <span class="docEmphasis">application ACK</span>. For example, in the following, the client sends its data to the server and then calls <TT>read</TT> for one byte of data:</P>
<pre>

</pre><pre>
char  ack;

Write(sockfd, data, nbytes);       /* data from client to server */
n = Read(sockfd, &amp;ack, 1);         /* wait for application-level ACK */
</pre><pre>
</pre>
<P class="docText">The server reads the data from the client and then sends back the one-byte application-level ACK:</P>
<pre>

</pre><pre>
nbytes = Read(sockfd, buff, sizeof(buff)); /* data from client */
         /* server verifies it received correct
            amount of data from client */
Write(sockfd, "", 1);           /* server's ACK back to client */
</pre><pre>
</pre>
<P class="docText">We are guaranteed that when the <TT>read</TT> in the client returns, the server process has read the data we sent. (This assumes that either the server knows how much data the client is sending, or there is some application-defined end-of-record marker, which we do not show here.) Here, the application-level ACK is a byte of 0, but the contents of this byte could be used to signal other conditions from the server to the client. <A class="docLink" HREF="#ch07fig11">Figure 7.11</A> shows the possible packet exchange.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig11"></A>Figure 7.11. Application ACK.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="299" src="FILES/07fig11.gif" ALT="graphics/07fig11.gif"></p>

</CENTER>
<P class="docText"><A class="docLink" HREF="#ch07fig12">Figure 7.12</A> summarizes the two possible calls to <TT>shutdown</TT> and the three possible calls to <TT>close</TT>, and the effect on a TCP socket.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig12"></A>Figure 7.12. Summary of <TT>shutdown</TT> and <TT>SO_LINGER</TT> scenarios.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="279" src="FILES/07fig12.jpg" ALT="graphics/07fig12.jpg"></p>

</CENTER>

<A NAME="ch07lev2sec7"></A>
<H4 class="docSection2Title"> <TT>SO_OOBINLINE</TT> Socket Option</H4>
<P class="docText">When this option is set, out-of-band data will be placed in the normal input queue (i.e., inline). When this occurs, the <TT>MSG_OOB</TT> flag to the receive functions cannot be used to read the out-of-band data. We will discuss out-of-band data in more detail in <A class="docLink" HREF="0131411551_ch24.html#ch24">Chapter 24</A>.</P>

<A NAME="ch07lev2sec8"></A>
<H4 class="docSection2Title"> <TT>SO_RCVBUF</TT> and <TT>SO_SNDBUF</TT> Socket Options</H4>
<P class="docText">Every socket has a send buffer and a receive buffer. We described the operation of the send buffers with TCP, UDP, and SCTP in <A class="docLink" HREF="0131411551_ch02lev1sec11.html#ch02fig15">Figures 2.15</A>, <A class="docLink" HREF="0131411551_ch02lev1sec11.html#ch02fig16">2.16</A>, and <A class="docLink" HREF="0131411551_ch02lev1sec11.html#ch02fig17">2.17</A>.</P>
<P class="docText">The receive buffers are used by TCP, UDP, and SCTP to hold received data until it is read by the application. With TCP, the available room in the socket receive buffer limits the window that TCP can advertise to the other end. The TCP socket receive buffer cannot overflow because the peer is not allowed to send data beyond the advertised window. This is TCP's flow control, and if the peer ignores the advertised window and sends data beyond the window, the receiving TCP discards it. With UDP, however, when a datagram arrives that will not fit in the socket receive buffer, that datagram is discarded. Recall that UDP has no flow control: It is easy for a fast sender to overwhelm a slower receiver, causing datagrams to be discarded by the receiver's UDP, as we will show in <A class="docLink" HREF="0131411551_ch08lev1sec13.html#ch08lev1sec13">Section 8.13</A>. In fact, a fast sender can overwhelm its own network interface, causing datagrams to be discarded by the sender itself.</P>
<P class="docText">These two socket options let us change the default sizes. The default values differ widely between implementations. Older Berkeley-derived implementations would default the TCP send and receive buffers to 4,096 bytes, but newer systems use larger values, anywhere from 8,192 to 61,440 bytes. The UDP send buffer size often defaults to a value around 9,000 bytes if the host supports NFS, and the UDP receive buffer size often defaults to a value around 40,000 bytes.</P>
<P class="docText">When setting the size of the TCP socket receive buffer, the ordering of the function calls is important. This is because of TCP's window scale option (<A class="docLink" HREF="0131411551_ch02lev1sec6.html#ch02lev1sec6">Section 2.6</A>), which is exchanged with the peer on the SYN segments when the connection is established. For a client, this means the <TT>SO_RCVBUF</TT> socket option must be set before calling <TT>connect</TT>. For a server, this means the socket option must be set for the listening socket before calling <TT>listen</TT>. Setting this option for the connected socket will have no effect whatsoever on the possible window scale option because <TT>accept</TT> does not return with the connected socket until TCP's three-way handshake is complete. That is why this option must be set for the listening socket. (The sizes of the socket buffers are always inherited from the listening socket by the newly created connected socket: pp. 462–463 of TCPv2.)</P>
<P class="docText">The TCP socket buffer sizes should be at least four times the MSS for the connection. If we are dealing with unidirectional data transfer, such as a file transfer in one direction, when we say "socket buffer sizes," we mean the socket send buffer size on the sending host and the socket receive buffer size on the receiving host. For bidirectional data transfer, we mean both socket buffer sizes on the sender and both socket buffer sizes on the receiver. With typical default buffer sizes of 8,192 bytes or larger, and a typical MSS of 512 or 1,460, this requirement is normally met.</P>
<BLOCKQUOTE><P><P class="docList">The minimum MSS multiple of four is a result of the way that TCP's fast recovery algorithm works. The TCP sender uses three duplicate acknowledgments to detect that a packet was lost (RFC 2581 [Allman, Paxson, and Stevens 1999]). The receiver sends a duplicate acknowledgment for each segment it receives after a lost segment. If the window size is smaller than four segments, there cannot be three duplicate acknowledgments, so the fast recovery algorithm cannot be invoked.</P></P></BLOCKQUOTE>
<P class="docText">To avoid wasting potential buffer space, the TCP socket buffer sizes should also be an even multiple of the MSS for the connection. Some implementations handle this detail for the application, rounding up the socket buffer size after the connection is established (p. 902 of TCPv2). This is another reason to set these two socket options before establishing a connection. For example, using the default 4.4BSD size of 8,192 and assuming an Ethernet with an MSS of 1,460, both socket buffers are rounded up to 8,760 (6 x 1,460) when the connection is established. This is not a crucial requirement; the additional space in the socket buffer above the multiple of the MSS is simply unused.</P>
<P class="docText">Another consideration in setting the socket buffer sizes deals with performance. <A class="docLink" HREF="#ch07fig13">Figure 7.13</A> shows a TCP connection between two endpoints (which we call a <span class="docEmphasis">pipe</span>) with a capacity of eight segments.</P>
<CENTER>
<H5 class="docFigureTitle"><A NAME="ch07fig13"></A>Figure 7.13. TCP connection (pipe) with a capacity of eight segments.</H5>

<p class="docText">
<IMG BORDER="0" id="132235130214" WIDTH="500" HEIGHT="69" src="FILES/07fig13.gif" ALT="graphics/07fig13.gif"></p>

</CENTER>
<P class="docText">We show four data segments on the top and four ACKs on the bottom. Even though there are only four segments of data in the pipe, the client must have a send buffer capacity of at least eight segments, because the client TCP must keep a copy of each segment until the ACK is received from the server.</P>
<BLOCKQUOTE><P><P class="docList">We are ignoring some details here. First, TCP's slow-start algorithm limits the rate at which segments are initially sent on an idle connection. Next, TCP often acknowledges every other segment, not every segment as we show. All these details are covered in Chapters 20 and 24 of TCPv1.</P></P></BLOCKQUOTE>
<P class="docText">What is important to understand is the concept of the full-duplex pipe, its capacity, and how that relates to the socket buffer sizes on both ends of the connection. The capacity of the pipe is called the <span class="docEmphasis">bandwidth-delay product</span> and we calculate this by multiplying the bandwidth (in bits/sec) times the RTT (in seconds), converting the result from bits to bytes. The RTT is easily measured with the <TT>ping</TT> program.</P>
<P class="docText">The bandwidth is the value corresponding to the slowest link between two endpoints and must somehow be known. For example, a T1 line (1,536,000 bits/sec) with an RTT of 60 ms gives a bandwidth-delay product of 11,520 bytes. If the socket buffer sizes are less than this, the pipe will not stay full, and the performance will be less than expected. Large socket buffers are required when the bandwidth gets larger (e.g., T3 lines at 45 Mbits/sec) or when the RTT gets large (e.g., satellite links with an RTT around 500 ms). When the bandwidth-delay product exceeds TCP's maximum normal window size (65,535 bytes), both endpoints also need the TCP <span class="docEmphasis">long fat pipe</span> options that we mentioned in <A class="docLink" HREF="0131411551_ch02lev1sec6.html#ch02lev1sec6">Section 2.6</A>.</P>
<BLOCKQUOTE><P><P class="docList">Most implementations have an upper limit for the sizes of the socket send and receive buffers, and sometimes this limit can be modified by the administrator. Older Berkeley-derived implementations had a hard upper limit of around 52,000 bytes, but newer implementations have a default limit of 256,000 bytes or more, and this can usually be increased by the administrator. Unfortunately, there is no simple way for an application to determine this limit. POSIX defines the <TT>fpathconf</TT> function, which most implementations support, and using the <TT>_PC_SOCK_MAXBUF</TT> constant as the second argument, we can retrieve the maximum size of the socket buffers. Alternately, an application can try setting the socket buffers to the desired value, and if that fails, cut the value in half and try again until it succeeds. Finally, an application should make sure that it's not actually making the socket buffer smaller when it sets it to a preconfigured "large" value; calling <TT>getsockopt</TT> first to retrieve the system's default and seeing if that's large enough is often a good start.</P></P></BLOCKQUOTE>

<A NAME="ch07lev2sec9"></A>
<H4 class="docSection2Title"> <TT>SO_RCVLOWAT</TT> and <TT>SO_SNDLOWAT</TT> Socket Options</H4>
<P class="docText">Every socket also has a receive low-water mark and a send low-water mark. These are used by the <TT>select</TT> function, as we described in <A class="docLink" HREF="0131411551_ch06lev1sec3.html#ch06lev1sec3">Section 6.3</A>. These two socket options, <TT>SO_RCVLOWAT</TT> and <TT>SO_SNDLOWAT</TT>, let us change these two low-water marks.</P>
<P class="docText">The receive low-water mark is the amount of data that must be in the socket receive buffer for <TT>select</TT> to return "readable." It defaults to 1 for TCP, UDP, and SCTP sockets. The send low-water mark is the amount of available space that must exist in the socket send buffer for <TT>select</TT> to return "writable." This low-water mark normally defaults to 2,048 for TCP sockets. With UDP, the low-water mark is used, as we described in <A class="docLink" HREF="0131411551_ch06lev1sec3.html#ch06lev1sec3">Section 6.3</A>, but since the number of bytes of available space in the send buffer for a UDP socket never changes (since UDP does not keep a copy of the datagrams sent by the application), as long as the UDP socket send buffer size is greater than the socket's low-water mark, the UDP socket is always writable. Recall from <A class="docLink" HREF="0131411551_ch02lev1sec11.html#ch02fig16">Figure 2.16</A> that UDP does not have a send buffer; it has only a send buffer size.</P>

<A NAME="ch07lev2sec10"></A>
<H4 class="docSection2Title"> <TT>SO_RCVTIMEO</TT> and <TT>SO_SNDTIMEO</TT> Socket Options</H4>
<P class="docText">These two socket options allow us to place a timeout on socket receives and sends. Notice that the argument to the two <TT>sockopt</TT> functions is a pointer to a <TT>timeval</TT> structure, the same one used with <TT>select</TT> (<A class="docLink" HREF="0131411551_ch06lev1sec3.html#ch06lev1sec3">Section 6.3</A>). This lets us specify the timeouts in seconds and microseconds. We disable a timeout by setting its value to 0 seconds and 0 microseconds. Both timeouts are disabled by default.</P>
<P class="docText">The receive timeout affects the five input functions: <TT>read</TT>, <TT>readv</TT>, <TT>recdv</TT>, <TT>recvfrom</TT>, and <TT>recvmsg</TT>. The send timeout affects the five output functions: <TT>write</TT>, <TT>writev</TT>, <TT>send</TT>, <TT>sendto</TT>, and <TT>sendmsg</TT>. We will talk more about socket timeouts in <A class="docLink" HREF="0131411551_ch14lev1sec2.html#ch14lev1sec2">Section 14.2</A>.</P>
<BLOCKQUOTE><P><P class="docList">These two socket options and the concept of inherent timeouts on socket receives and sends were added with 4.3BSD Reno.</P></P><P><P class="docList">In Berkeley-derived implementations, these two values really implement an inactivity timer and not an absolute timer on the read or write system call. Pages 496 and 516 of TCPv2 talk about this in more detail.</P></P></BLOCKQUOTE>

<A NAME="ch07lev2sec11"></A>
<H4 class="docSection2Title"> <TT>SO_REUSEADDR</TT> and <TT>SO_REUSEPORT</TT> Socket Options</H4>
<P class="docText">The <TT>SO_REUSEADDR</TT> socket option serves four different purposes:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList"><TT>SO_REUSEADDR</TT> allows a listening server to start and <TT>bind</TT> its well-known port, even if previously established connections exist that use this port as their local port. This condition is typically encountered as follows:</P><span style="font-weight:bold"><OL class="docList" TYPE="a"><LI><span style="font-weight:normal"><P class="docList">A listening server is started.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">A connection request arrives and a child process is spawned to handle that client.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">The listening server terminates, but the child continues to service the client on the existing connection.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">The listening server is restarted.</P><P class="docList">By default, when the listening server is restarted in (d) by calling <TT>socket</TT>, <TT>bind</TT>, and <TT>listen</TT>, the call to <TT>bind</TT> fails because the listening server is trying to bind a port that is part of an existing connection (the one being handled by the previously spawned child). But if the server sets the <TT>SO_REUSEADDR</TT> socket option between the calls to <TT>socket</TT> and <TT>bind</TT>, the latter function will succeed. <span class="docEmphasis">All</span> TCP servers should specify this socket option to allow the server to be restarted in this situation.</P></span></LI></OL></span><blockquote>
<p class="docText">This scenario is one of the most frequently asked questions on USENET.</p>
</blockquote></span></LI><LI><span style="font-weight:normal"><P class="docList"><TT>SO_REUSEADDR</TT> allows a new server to be started on the same port as an existing server that is bound to the wildcard address, as long as each instance binds a different local IP address. This is common for a site hosting multiple HTTP servers using the IP alias technique (<A class="docLink" HREF="0131411551_app01lev1sec4.html#app01lev1sec4">Section A.4</A>). Assume the local host's primary IP address is 198.69.10.2 but it has two aliases: 198.69.10.128 and 198.69.10.129. Three HTTP servers are started. The first HTTP server would call <TT>bind</TT> with the wildcard as the local IP address and a local port of 80 (the well-known port for HTTP). The second server would call <TT>bind</TT> with a local IP address of 198.69.10.128 and a local port of 80. But, this second call to <TT>bind</TT> fails unless <TT>SO_REUSEADDR</TT> is set before the call. The third server would <TT>bind</TT> 198.69.10.129 and port 80. Again, <TT>SO_REUSEADDR</TT> is required for this final call to succeed. Assuming <TT>SO_REUSEADDR</TT> is set and the three servers are started, incoming TCP connection requests with a destination IP address of 198.69.10.128 and a destination port of 80 are delivered to the second server, incoming requests with a destination IP address of 198.69.10.129 and a destination port of 80 are delivered to the third server, and all other TCP connection requests with a destination port of 80 are delivered to the first server. This "default" server handles requests destined for 198.69.10.2 in addition to any other IP aliases that the host may have configured. The wildcard means "everything that doesn't have a better (more specific) match." Note that this scenario of allowing multiple servers for a given service is handled automatically if the server always sets the <TT>SO_REUSEADDR</TT> socket option (as we recommend).</P><P class="docList">With TCP, we are never able to start multiple servers that <TT>bind</TT> the same IP address and the same port: a <span class="docEmphasis">completely duplicate binding</span>. That is, we cannot start one server that binds 198.69.10.2 port 80 and start another that also binds 198.69.10.2 port 80, even if we set the <TT>SO_REUSEADDR</TT> socket option for the second server.</P><P class="docList">For security reasons, some operating systems prevent <span class="docEmphasis">any</span> "more specific" bind to a port that is already bound to the wildcard address, that is, the series of binds described here would not work with or without <TT>SO_REUSEADDR</TT>. On such a system, the server that performs the wildcard bind must be started last. This is to avoid the problem of a rogue server binding to an IP address and port that are being served already by a system service and intercepting legitimate requests. This is a particular problem for NFS, which generally does not use a privileged port.</P></span></LI><LI><span style="font-weight:normal"><P class="docList"><TT>SO_REUSEADDR</TT> allows a single process to bind the same port to multiple sockets, as long as each bind specifies a different local IP address. This is common for UDP servers that need to know the destination IP address of client requests on systems that do not provide the <TT>IP_RECVDSTADDR</TT> socket option. This technique is normally not used with TCP servers since a TCP server can always determine the destination IP address by calling <TT>getsockname</TT> after the connection is established. However, a TCP server wishing to serve connections to some, but not all, addresses belonging to a multihomed host should use this technique.</P></span></LI><LI><span style="font-weight:normal"><P class="docList"><TT>SO_REUSEADDR</TT> allows <span class="docEmphasis">completely duplicate bindings</span>: a <TT>bind</TT> of an IP address and port, when that same IP address and port are already bound to another socket, if the transport protocol supports it. Normally this feature is supported only for UDP sockets.</P><P class="docList">This feature is used with multicasting to allow the same application to be run multiple times on the same host. When a UDP datagram is received for one of these multiply bound sockets, the rule is that if the datagram is destined for either a broadcast address or a multicast address, one copy of the datagram is delivered to each matching socket. But if the datagram is destined for a unicast address, the datagram is delivered to only one socket. If, in the case of a unicast datagram, there are multiple sockets that match the datagram, the choice of which socket receives the datagram is implementation-dependent. Pages <span class="docEmphasis">777–779</span> of TCPv2 talk more about this feature. We will talk more about broadcasting and multicasting in <A class="docLink" HREF="0131411551_ch20.html#ch20">Chapters 20</A> and <A class="docLink" HREF="0131411551_ch21.html#ch21">21</A>.</P></span></LI></OL></span>
<P class="docText"><A class="docLink" HREF="0131411551_ch07lev1sec13.html#ch07lev1sec13">Exercises 7.5</A> and <A class="docLink" HREF="0131411551_ch07lev1sec13.html#ch07lev1sec13">7.6</A> show some examples of this socket option.</P>
<P class="docText">4.4BSD introduced the <TT>SO_REUSEPORT</TT> socket option when support for multicasting was added. Instead of overloading <TT>SO_REUSEADDR</TT> with the desired multicast semantics that allow completely duplicate bindings, this new socket option was introduced with the following semantics:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList">This option allows completely duplicate bindings, but only if each socket that wants to bind the same IP address and port specify this socket option.</P></span></LI><LI><span style="font-weight:normal"><P class="docList"><TT>SO_REUSEADDR</TT> is considered equivalent to <TT>SO_REUSEPORT</TT> if the IP address being bound is a multicast address (p. 731 of TCPv2).</P></span></LI></OL></span>
<P class="docText">The problem with this socket option is that not all systems support it, and on those that do not support the option but do support multicasting, <TT>SO_REUSEADDR</TT> is used instead of <TT>SO_REUSEPORT</TT> to allow completely duplicate bindings when it makes sense (i.e., a UDP server that can be run multiple times on the same host at the same time and that expects to receive either broadcast or multicast datagrams).</P>
<P class="docText">We can summarize our discussion of these socket options with the following recommendations:</P>
<span style="font-weight:bold"><OL class="docList" TYPE="1"><LI><span style="font-weight:normal"><P class="docList">Set the <TT>SO_REUSEADDR</TT> socket option before calling <TT>bind</TT> in all TCP servers.</P></span></LI><LI><span style="font-weight:normal"><P class="docList">When writing a multicast application that can be run multiple times on the same host at the same time, set the <TT>SO_REUSEADDR</TT> socket option and bind the group's multicast address as the local IP address.</P></span></LI></OL></span>
<P class="docText">Chapter 22 of TCPv2 talks about these two socket options in more detail.</P>
<P class="docText">There is a potential security problem with <TT>SO_REUSEADDR</TT>. If a socket exists that is bound to, say, the wildcard address and port 5555, if we specify <TT>SO_REUSEADDR</TT>, we can bind that same port to a different IP address, say the primary IP address of the host. Any future datagrams that arrive destined to port 5555 and the IP address that we bound to our socket are delivered to our socket, not to the other socket bound to the wildcard address. These could be TCP SYN segments, SCTP INIT chunks, or UDP datagrams. (<A class="docLink" HREF="0131411551_ch11lev1sec23.html#ch11lev1sec23">Exercises 11.9</A> shows this feature with UDP.) For most well-known services, HTTP, FTP, and Telnet, for example, this is not a problem because these servers all bind a reserved port. Hence, any process that comes along later and tries to bind a more specific instance of that port (i.e., steal the port) requires superuser privileges. NFS, however, can be a problem since its normal port (2049) is not reserved.</P>
<BLOCKQUOTE><P><P class="docList">One underlying problem with the sockets API is that the setting of the socket pair is done with two function calls (<TT>bind</TT> and <TT>connect</TT>) instead of one. [Torek 1994] proposes a single function that solves this problem.</P><P><TABLE CELLSPACING="0" FRAME="void" RULES="none" CELLPADDING="5" WIDTH="90%"><COLGROUP align="left" span="1"><THEAD></THEAD><TR><TD class="docTableCell" valign="top"><P class="docText"><TT>int bind_connect_listen(int</TT> <span class="docEmphasis">sockfd</span>, <TT>const struct sockaddr</TT> *<span class="docEmphasis">laddr</span>, <TT>int</TT> <span class="docEmphasis">laddrlen</span>, <TT>const struct sockaddr</TT> *<span class="docEmphasis">faddr</span>, <TT>int</TT> <span class="docEmphasis">faddrlen</span>, <TT>int</TT> <span class="docEmphasis">listen</span><TT>);</TT></P></TD></TR></COLGROUP></TABLE></P></P><P><P class="docList"><span class="docEmphasis">laddr</span> specifies the local IP address and local port, <span class="docEmphasis">faddr</span> specifies the foreign IP address and foreign port, and <span class="docEmphasis">listen</span> specifies a client (zero) or a server (nonzero; same as the backlog argument to <TT>listen</TT>). Then, <TT>bind</TT> would be a library function that calls this function with <span class="docEmphasis">faddr</span> a null pointer and <span class="docEmphasis">faddrlen</span> 0, and <TT>connect</TT> would be a library function that calls this function with <span class="docEmphasis">laddr</span> a null pointer and <span class="docEmphasis">laddrlen</span> 0. There are a few applications, notably TFTP, that need to specify both the local pair and the foreign pair, and they could call <TT>bind_connect_listen</TT> directly. With such a function, the need for <TT>SO_REUSEADDR</TT> disappears, other than for multicast UDP servers that explicitly need to allow completely duplicate bindings of the same IP address and port. Another benefit of this new function is that a TCP server could restrict itself to servicing connection requests that arrive from one specific IP address and port, something which RFC 793 [Postel 1981c] specifies but is impossible to implement with the existing sockets API.</P></P></BLOCKQUOTE>

<A NAME="ch07lev2sec12"></A>
<H4 class="docSection2Title"> <TT>SO_TYPE</TT> Socket Option</H4>
<P class="docText">This option returns the socket type. The integer value returned is a value such as <TT>SOCK_STREAM</TT> or <TT>SOCK_DGRAM</TT>. This option is typically used by a process that inherits a socket when it is started.</P>

<A NAME="ch07lev2sec13"></A>
<H4 class="docSection2Title"> <TT>SO_USELOOPBACK</TT> Socket Option</H4>
<P class="docText">This option applies only to sockets in the routing domain (<TT>AF_ROUTE</TT>). This option defaults to ON for these sockets (the only one of the <TT>SO</TT>_<span class="docEmphasis">xxx</span> socket options that defaults to ON instead of OFF). When this option is enabled, the socket receives a copy of everything sent on the socket.</P>
<BLOCKQUOTE><P><P class="docList">Another way to disable these loopback copies is to call <TT>shutdown</TT> with a second argument of <TT>SHUT_RD</TT>.</P></P></BLOCKQUOTE>


<ul></ul></td></tr></table>
<td></td>
<table width="100%" border="0" cellspacing="0" cellpadding="0">
<td class="tt1"><a href="NFO/lib.html">[ Team LiB ]</a></td><td valign="top" class="tt1" align="right">
          <a href="0131411551_ch07lev1sec4.html"><img src="FILES/btn_prev.gif" width="62" height="15" border="0" align="absmiddle" alt="Previous Section"></a>
          <a href="0131411551_ch07lev1sec6.html"><img src="FILES/btn_next.gif" width="41" height="15" border="0" align="absmiddle" alt="Next Section"></a>
</td></table>
</body></html>
